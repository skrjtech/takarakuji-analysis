{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9956eb3-709f-4a07-b6b4-024b374ec886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import transforms\n",
    "# from torchinfo import summary #torchinfoはニューラルネットの中身を見れるのでおすすめ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef93bf3b-981b-4b72-8ba0-b1a680dd67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"miniloto.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"].map(lambda x: str(x).replace(\"年\", \"-\").replace(\"月\", \"-\").replace(\"日\", \"-\")))\n",
    "df = df.drop_duplicates(\"date\")\n",
    "df = df.set_index(\"date\")\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "values = 5\n",
    "valColm = [f\"val{i}\" for i in range(1, values+1)]\n",
    "data = df[valColm].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e43d035-7469-4448-bfac-d31e6746bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "df_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157652b0-fcd4-44e1-8ec3-d9f73c2ce9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.04166667, 0.53846154, 0.61538462, 0.71428571],\n",
       "       [0.04347826, 0.375     , 0.34615385, 0.65384615, 0.95238095],\n",
       "       [0.        , 0.25      , 0.26923077, 0.76923077, 0.95238095],\n",
       "       ...,\n",
       "       [0.08695652, 0.125     , 0.15384615, 0.53846154, 0.47619048],\n",
       "       [0.08695652, 0.33333333, 0.30769231, 0.34615385, 0.19047619],\n",
       "       [0.        , 0.125     , 0.53846154, 0.57692308, 0.61904762]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88cd4cac-1dde-4c85-9d7f-97420a57bc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 711, test size: 305 \n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df_scaled) * 0.70) #学習サイズ(100個)\n",
    "test_size = len(df_scaled) - train_size #全データから学習サイズを引けばテストサイズになる\n",
    "train = df_scaled[0:train_size,:] #全データから学習の個所を抜粋\n",
    "test = df_scaled[train_size:len(df_scaled),:] #全データからテストの個所を抜粋\n",
    "print(\"train size: {}, test size: {} \".format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23830e57-263e-4266-a1b9-04ae9342baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 5)\n",
      "(705, 5)\n"
     ]
    }
   ],
   "source": [
    "time_stemp = 5 #今回は10個のシーケンシャルデータを1固まりとするので10を設定\n",
    "n_sample = train_size - time_stemp - 1 #学習予測サンプルはt=10~99なので89個\n",
    "\n",
    "#シーケンシャルデータの固まり数、シーケンシャルデータの長さ、RNN_cellへの入力次元(1次元)に形を成形\n",
    "input_data = np.zeros((n_sample, time_stemp)) #シーケンシャルデータを格納する箱を用意(入力)\n",
    "correct_input_data = np.zeros((n_sample, time_stemp)) #シーケンシャルデータを格納する箱を用意(正解)\n",
    "\n",
    "print(input_data.shape)\n",
    "print(correct_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "433ca5c8-a7f8-4b66-b713-bb6d5c857fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_sample - 1):\n",
    "    input_data[i] = df_scaled[i]\n",
    "    correct_input_data[i] = df_scaled[i + 1]\n",
    "\n",
    "input_data = torch.tensor(input_data.reshape(-1, 5, 1), dtype=torch.float) #Tensor化(入力)\n",
    "correct_data = torch.tensor(correct_input_data, dtype=torch.float) #Tensor化(正解)\n",
    "dataset = torch.utils.data.TensorDataset(input_data, correct_data) #データセット作成\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True) #データローダー作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bff7db1-9f56-4220-808e-9aaddfe0e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_rnn_net(\n",
      "  (rnn): RNN(1, 64, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class My_rnn_net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(My_rnn_net, self).__init__()\n",
    "\n",
    "        self.input_size = input_size #入力データ(x)\n",
    "        self.hidden_dim = hidden_dim #隠れ層データ(hidden)\n",
    "        self.n_layers = n_layers #RNNを「上方向に」何層重ねるか？の設定 ※横方向ではない\n",
    "        \"\"\"\n",
    "        PyTorchのRNNユニット。batch_first=Trueでバッチサイズを最初にくるように設定\n",
    "        また、先程示した図ではRNN_cellが複数あったがここではRNNが1個しかない。\n",
    "　　　　 つまりこの「nn.RNN」は複数のRNN_cellをひとまとめにしたものである。\n",
    "　　　　 ※シーケンシャルデータと初期値のhiddenだけ入れてあげれば内部で勝手に計算してくれる\n",
    "　　　　 ※出力部は各時刻毎に出力されるが、下で述べているように最後の時刻しか使用しない\n",
    "        \"\"\"\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size) #全結合層でhiddenからの出力を1個にする\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        #y_rnn, h = self.rnn(x, h0)\n",
    "        y_rnn, h = self.rnn(x, None) #hidden部分はコメントアウトした↑2行と同じ意味になっている。\n",
    "\n",
    "        y = self.fc(y_rnn[:, -1, :]) #最後の時刻の出力だけを使用するので「-1」としている\n",
    "\n",
    "        return y\n",
    "\n",
    "#RNNの設定\n",
    "n_inputs  = 1\n",
    "n_outputs = 5\n",
    "n_hidden  = 64 #隠れ層(hidden)を64個に設定\n",
    "n_layers  = 3\n",
    "\n",
    "net = My_rnn_net(n_inputs, n_outputs, n_hidden, n_layers) #RNNをインスタンス化\n",
    "print(net) #作成したRNNの層を簡易表示\n",
    "\n",
    "#おすすめのtorchinfoでさらに見やすく表示\n",
    "batch_size = 32\n",
    "# summary(net, (batch_size, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50b4665d-2f83-4a94-803d-dcbdc542b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0457,  0.0696,  0.1571, -0.0338, -0.1370]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.rand(1, 5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3613edf9-3e75-44a2-a98a-83b5ef7591ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc = nn.MSELoss() #損失関数はMSE\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #オプティマイザはAdam\n",
    "loss_record = [] #lossの推移記録用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda. is_available() else \"cpu\")  #デバイス(GPU or CPU)設定 \n",
    "epochs = 2000 #エポック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7295cf1a-389b-41aa-aae7-ee0eb49c06d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My_rnn_net(\n",
       "  (rnn): RNN(1, 64, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device) #モデルをGPU(CPU)へ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba331fd9-c20d-4891-a63e-0137602ed5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss_Train: 0.08970630950415912 eval: 0.3404255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Loss_Train: 0.03803934343159199 eval: 0.37446808510638296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 Loss_Train: 0.03878204160086487 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 Loss_Train: 0.03916867676636447 eval: 0.3801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400 Loss_Train: 0.042761975737369576 eval: 0.3645390070921986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500 Loss_Train: 0.038283577107864876 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600 Loss_Train: 0.03747205525312735 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700 Loss_Train: 0.03778689759580985 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800 Loss_Train: 0.041929344282202095 eval: 0.37163120567375885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900 Loss_Train: 0.03735723314077958 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 Loss_Train: 0.037984072676171425 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100 Loss_Train: 0.0374406173258372 eval: 0.3702127659574468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200 Loss_Train: 0.03772758522435375 eval: 0.3801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300 Loss_Train: 0.04018267551841943 eval: 0.37446808510638296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1400 Loss_Train: 0.038517471321898956 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500 Loss_Train: 0.03826950425687044 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600 Loss_Train: 0.03776915824931601 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700 Loss_Train: 0.03991316841996234 eval: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1800 Loss_Train: 0.03861230951936349 eval: 0.3702127659574468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1900 Loss_Train: 0.047628883434378586 eval: 0.36879432624113473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34480/1140821471.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 Loss_Train: 0.03760800555186427 eval: 0.3702127659574468\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs+1):\n",
    "    net.train() #学習モード\n",
    "    running_loss =0.0 #記録用loss初期化\n",
    "    for j, (x, t) in enumerate(train_loader): #データローダからバッチ毎に取り出す\n",
    "        x = x.to(device) * torch.rand_like(x) #シーケンシャルデータをバッチサイズ分だけGPUへ\n",
    "        optimizer.zero_grad() #勾配を初期化\n",
    "        y = net(x) #RNNで予測\n",
    "        y = y.to('cpu') #予測結果をCPUに戻す\n",
    "        loss = loss_fnc(y, t) #MSEでloss計算\n",
    "        loss.backward()  #逆伝番        \n",
    "        optimizer.step()  #勾配を更新        \n",
    "        running_loss += loss.item()  #バッチごとのlossを足していく\n",
    "    running_loss /= j+1 #lossを平均化\n",
    "    loss_record.append(running_loss) #記録用のlistにlossを加える\n",
    "\n",
    "    \"\"\"以下RNNの学習の経過を可視化するコード\"\"\"\n",
    "    if i%100 == 0: #今回は100エポック毎に学習がどう進んだか？を表示させる\n",
    "        input_train = input_data[0].reshape(-1, 5, 1) #まず最初にt＝0～9をlist化しておく\n",
    "        net.eval() #予測モード\n",
    "        result = []\n",
    "        for k in range(n_sample): #学習させる点の数だけループ\n",
    "            x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n",
    "            x = x.reshape(1, time_stemp, 1) #予測なので当然バッチサイズは1\n",
    "            x = x.to(device).float() #GPUへ\n",
    "            y = net(x) #予測\n",
    "            y = y.to('cpu') #結果をCPUへ戻す\n",
    "            \n",
    "            y_ = scaler.inverse_transform(y.detach().numpy()).astype(int)\n",
    "            t = scaler.inverse_transform(correct_data[k].reshape(1, -1).detach().numpy())\n",
    "            res = np.mean(np.sum(y_ == t, axis=-1))\n",
    "            result.append(res)\n",
    "            input_train = y.detach().numpy()\n",
    "        print('Epoch:', i, 'Loss_Train:', running_loss, 'eval:', np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdd73ead-d1cd-49e9-ab2e-395c86d6653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f238aaebc10>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c19c1b1b-7ce7-429a-b2f3-be8974179c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 11 16 21 26]]\n",
      "[[ 1  2  3  4 10]]\n"
     ]
    }
   ],
   "source": [
    "index = -1\n",
    "x = input_data[index].reshape(1, -1)\n",
    "x = torch.tensor(input_train) #最新の10個のデータを取り出してTensor化\n",
    "x = x.reshape(1, time_stemp, 1) #予測なので当然バッチサイズは1\n",
    "x = x.to(device).float() #GPUへ\n",
    "y = net(x) #予測\n",
    "y = y.to('cpu') #結果をCPUへ戻す\n",
    "\n",
    "y_ = scaler.inverse_transform(y.detach().numpy()).astype(int)\n",
    "t = scaler.inverse_transform(correct_data[index].reshape(1, -1).detach().numpy()).astype(int)\n",
    "print(y_)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71af880-bc2f-47cc-b3ee-8000fc55ca18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d68bff-ff0c-4754-95a8-5cdad9f00954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
